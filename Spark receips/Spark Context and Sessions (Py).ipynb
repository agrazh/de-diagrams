{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "406db2d5-dd03-4006-9312-d66191f3c4c1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bf95dfa-f8d5-4456-8ee0-4d42149919f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "# create SparkConf object\n",
    "conf = SparkConf().setAppName(\"myApp\").setMaster(\"local[*]\")  # use all available logical CPU cores\n",
    "sc = SparkContext(conf=conf)  # or SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
    "rdd.collect()\n",
    "\n",
    "# get SparkContext settings in Spark 1.x, 2.x\n",
    "sc.getConf().getAll()\n",
    "sc.getConf().get(\"spark.app.name\")\n",
    "\n",
    "# stop SparkContext and restart the driver\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23300ed4-c7f5-422d-b611-528eb2a3dc1a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Spark Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e7b8205-fa9b-48e5-b709-a31922ed9f4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# create Sessions\n",
    "spark1 = SparkSession.builder.appName(\"Session1\")  # or `SparkSession.builder.appName(\"Session1\").getOrCreate()`\n",
    "spark2 = SparkSession.builder.appName(\"Session2\") \\\n",
    "    .config(\"spark.some.setting\", \"value2\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\")\n",
    "\n",
    "# get SparkContext settings in Spark 2.x\n",
    "spark1.sparkContext.getConf().getAll()\n",
    "spark2.sparkContext.getConf().get(\"spark.app.name\")\n",
    "\n",
    "# stop the underlying SparkContext and both sessions `spark1`, `spark2`\n",
    "spark1.stop()  # == spark1.sparkContext.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b78e4a1-e055-4b77-aafd-6d6358a6b651",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Two Sessions with distinct tables [Demo]\n",
    "\n",
    "Session: `spark1` , `spark2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5319181d-ad59-405d-bb8b-3d3784ce91cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create new sessions\n",
    "spark1 = spark.newSession()\n",
    "spark2 = spark.newSession()\n",
    "\n",
    "#  get \"spark1\" and \"spark2\" session ids. They are different\n",
    "print(spark1)\n",
    "print(spark2)\n",
    "\n",
    "# get session contexts. They are the same\n",
    "print(spark1.sparkContext)\n",
    "print(spark2.sparkContext)\n",
    "\n",
    "#  create tables in both sessions\n",
    "spark1.range(100).createOrReplaceTempView(\"vtable_1\")\n",
    "spark2.range(100).createOrReplaceTempView(\"vtable_2\")\n",
    "\n",
    "# list all tables in both sessions\n",
    "spark1.catalog.listTables()  # or `spark1.sql(\"show tables\").show()`\n",
    "spark2.catalog.listTables()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Spark Context and Sessions (Py)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
